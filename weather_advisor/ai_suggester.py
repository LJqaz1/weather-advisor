# weather_advisor/ai_suggester.py
import argparse
import os
import json
import datetime
from typing import Optional


def build_enhanced_prompt(
    city: str, temp: float, desc: str, time_remark: str, lang: str = "ja"
) -> str:
    """
    æ„å»ºå¢å¼ºç‰ˆAIæç¤ºè¯ï¼ŒåŒ…å«ä¸ªæ€§åŒ–ä¿¡æ¯
    """
    current_hour = datetime.datetime.now().hour
    month = datetime.datetime.now().month

    # ç¡®å®šæ—¶é—´æ®µå’Œå­£èŠ‚
    if 5 <= current_hour <= 11:
        time_period = "morning"
    elif 12 <= current_hour <= 17:
        time_period = "afternoon"
    elif 18 <= current_hour <= 23:
        time_period = "evening"
    else:
        time_period = "night"

    if month in [12, 1, 2]:
        season = "winter"
    elif month in [3, 4, 5]:
        season = "spring"
    elif month in [6, 7, 8]:
        season = "summer"
    else:
        season = "autumn"

    # åœ°åŸŸç‰¹è‰²æç¤º
    regional_context = {
        "tokyo": "high humidity area",
        "osaka": "windy conditions common",
        "kyoto": "temperature fluctuations due to basin location",
        "london": "frequent light rain",
        "paris": "cobblestone streets",
        "new york": "windy between buildings",
        "beijing": "dusty conditions and air quality concerns",
        "shanghai": "high humidity and frequent rain",
        "singapore": "extremely hot and humid year-round",
    }

    region_hint = ""
    for city_key, context in regional_context.items():
        if city_key in city.lower():
            region_hint = f" Note: {city} is known for {context}."
            break

    prompts = {
        "en": f"""You are a professional styling consultant with expertise in weather-appropriate fashion. 

Current Context:
- Location: {city}{region_hint}
- Temperature: {temp}â„ƒ
- Weather: {desc}
- Time: {time_period} ({time_remark})
- Season: {season}

Provide ONE concise, practical clothing recommendation that considers:
1. Temperature comfort and layering
2. Weather protection needs
3. Time-appropriate styling
4. Seasonal fashion trends
5. Regional climate characteristics

Response should be specific, actionable, and under 25 words.""",
        "zh": f"""ä½ æ˜¯ä¸“ä¸šçš„æ—¶å°šé€ å‹é¡¾é—®ï¼Œä¸“é—¨æä¾›é€‚åˆå¤©æ°”çš„ç©¿æ­å»ºè®®ã€‚

å½“å‰æƒ…å†µï¼š
- åœ°ç‚¹ï¼š{city}{region_hint}
- æ°”æ¸©ï¼š{temp}â„ƒ
- å¤©æ°”ï¼š{desc}
- æ—¶é—´ï¼š{time_period}ï¼ˆ{time_remark}ï¼‰
- å­£èŠ‚ï¼š{season}

è¯·æä¾›ä¸€æ¡ç®€æ´å®ç”¨çš„ç©¿è¡£å»ºè®®ï¼Œéœ€è¦è€ƒè™‘ï¼š
1. æ¸©åº¦èˆ’é€‚æ€§å’Œå±‚æ¬¡æ­é…
2. å¤©æ°”é˜²æŠ¤éœ€æ±‚
3. æ—¶é—´æ®µåˆé€‚æ€§
4. å­£èŠ‚æ—¶å°šè¶‹åŠ¿
5. åœ°åŸŸæ°”å€™ç‰¹ç‚¹

å›ç­”è¦å…·ä½“ã€å¯è¡Œï¼Œæ§åˆ¶åœ¨25å­—ä»¥å†…ã€‚""",
        "ja": f"""ã‚ãªãŸã¯å¤©å€™ã«é©ã—ãŸãƒ•ã‚¡ãƒƒã‚·ãƒ§ãƒ³ã®å°‚é–€ã‚¹ã‚¿ã‚¤ãƒªã‚¹ãƒˆã§ã™ã€‚

ç¾åœ¨ã®çŠ¶æ³ï¼š
- å ´æ‰€ï¼š{city}{region_hint}
- æ°—æ¸©ï¼š{temp}â„ƒ
- å¤©æ°—ï¼š{desc}
- æ™‚é–“å¸¯ï¼š{time_period}ï¼ˆ{time_remark}ï¼‰
- å­£ç¯€ï¼š{season}

ä»¥ä¸‹ã‚’è€ƒæ…®ã—ãŸç°¡æ½”ã§å®Ÿç”¨çš„ãªæœè£…ææ¡ˆã‚’1ã¤ãŠé¡˜ã„ã—ã¾ã™ï¼š
1. æ°—æ¸©ã«ã‚ˆã‚‹å¿«é©æ€§ã¨é‡ã­ç€
2. å¤©å€™ã«å¯¾ã™ã‚‹é˜²è­·
3. æ™‚é–“å¸¯ã«é©ã—ãŸã‚¹ã‚¿ã‚¤ãƒ«
4. å­£ç¯€ã®ãƒˆãƒ¬ãƒ³ãƒ‰
5. åœ°åŸŸã®æ°—å€™ç‰¹æ€§

25æ–‡å­—ä»¥å†…ã§ã€å…·ä½“çš„ã§å®Ÿè¡Œå¯èƒ½ãªææ¡ˆã‚’ã—ã¦ãã ã•ã„ã€‚""",
    }

    return prompts.get(lang, prompts["ja"])


def build_prompt(
    city: str, temp: float, desc: str, time_remark: str, lang: str = "ja"
) -> str:
    """
    æ„å»ºAIæç¤ºè¯ï¼Œæ”¯æŒå¤šè¯­è¨€ - ä¿æŒå‘åå…¼å®¹æ€§
    """
    # ä½¿ç”¨å¢å¼ºç‰ˆæç¤ºè¯
    return build_enhanced_prompt(city, temp, desc, time_remark, lang)


def call_ollama_gemma(prompt: str) -> Optional[str]:
    """
    è°ƒç”¨ Ollama + Gemma æ¨¡å‹
    """
    try:
        import requests
        import json

        # Ollama é»˜è®¤è¿è¡Œåœ¨ localhost:11434
        ollama_url = os.getenv("OLLAMA_URL", "http://localhost:11434")
        model_name = os.getenv("OLLAMA_MODEL", "gemma:7b")  # å¯é…ç½®æ¨¡å‹ç‰ˆæœ¬

        if os.getenv("DEBUG_MODE") == "True":
            print(f"ğŸ¤– è°ƒç”¨ Ollama Gemma æ¨¡å‹ä¸­... (æ¨¡å‹: {model_name})")

        # æ„å»ºè¯·æ±‚æ•°æ®
        data = {
            "model": model_name,
            "prompt": prompt,
            "stream": False,  # ä¸ä½¿ç”¨æµå¼è¾“å‡ºï¼Œç›´æ¥è·å–å®Œæ•´å“åº”
            "options": {
                "temperature": 0.7,
                "top_p": 0.9,
                "max_tokens": 150,
                "stop": ["\n\n", "ã€‚ã€‚", ".."],  # é˜²æ­¢è¿‡é•¿å›ç­”
            },
        }

        # å‘é€è¯·æ±‚åˆ° Ollama
        response = requests.post(
            f"{ollama_url}/api/generate",
            json=data,
            timeout=30,  # æœ¬åœ°æ¨¡å‹å¯èƒ½éœ€è¦è¾ƒé•¿æ—¶é—´
        )

        if response.status_code == 200:
            result = response.json()
            suggestion = result.get("response", "").strip()

            if suggestion:
                # æ¸…ç†å¯èƒ½çš„æ ¼å¼é—®é¢˜
                suggestion = suggestion.replace("\n", " ").strip()
                return suggestion
            else:
                print("âŒ Ollama è¿”å›ç©ºå“åº”")
                return None
        else:
            print(f"âŒ Ollama API é”™è¯¯: {response.status_code} - {response.text}")
            return None

    except ImportError:
        print("âŒ æœªå®‰è£… requests åº“ï¼Œè¯·è¿è¡Œ: pip install requests")
        return None
    except requests.exceptions.ConnectionError:
        print("âŒ æ— æ³•è¿æ¥åˆ° Ollama æœåŠ¡ï¼Œè¯·ç¡®ä¿ Ollama æ­£åœ¨è¿è¡Œ")
        print("   å¯åŠ¨ Ollama: ollama serve")
        print(f"   ä¸‹è½½æ¨¡å‹: ollama pull {os.getenv('OLLAMA_MODEL', 'gemma:7b')}")
        return None
    except requests.exceptions.Timeout:
        print("âŒ Ollama è¯·æ±‚è¶…æ—¶ï¼Œæ¨¡å‹å¯èƒ½æ­£åœ¨åŠ è½½ä¸­...")
        return None
    except Exception as e:
        print(f"âŒ Ollama è°ƒç”¨å¤±è´¥: {e}")
        return None


def call_openai_api(prompt: str) -> Optional[str]:
    """
    è°ƒç”¨ OpenAI API
    """
    try:
        import openai

        openai_api_key = os.getenv("OPENAI_API_KEY")
        if not openai_api_key:
            print("âŒ æœªæ‰¾åˆ° OpenAI API å¯†é’¥ï¼Œè¯·è®¾ç½® OPENAI_API_KEY ç¯å¢ƒå˜é‡")
            return None

        client = openai.OpenAI(api_key=openai_api_key)

        response = client.chat.completions.create(
            model=os.getenv("OPENAI_MODEL", "gpt-3.5-turbo"),
            messages=[
                {
                    "role": "system",
                    "content": "You are a helpful and concise clothing advisor.",
                },
                {"role": "user", "content": prompt},
            ],
            max_tokens=100,
            temperature=0.7,
        )

        suggestion = response.choices[0].message.content.strip()
        return suggestion

    except ImportError:
        print("âŒ æœªå®‰è£… openai åº“ï¼Œè¯·è¿è¡Œ: pip install openai")
        return None
    except Exception as e:
        print(f"âŒ OpenAI API è°ƒç”¨å¤±è´¥: {e}")
        return None


def get_ai_suggestion(
    city: str,
    temp: float,
    desc: str,
    time_remark: str,
    lang: str = "ja",
    ai_mode: str = "ollama",
) -> Optional[str]:
    """
    è·å–AIå»ºè®®
    """
    prompt = build_enhanced_prompt(city, temp, desc, time_remark, lang)

    if ai_mode == "ollama" or ai_mode == "local":  # å…¼å®¹åŸæœ‰çš„ 'local' å‚æ•°
        return call_ollama_gemma(prompt)
    elif ai_mode == "openai":
        return call_openai_api(prompt)
    else:
        print(f"âŒ ä¸æ”¯æŒçš„AIæ¨¡å¼: {ai_mode}")
        return None


def parse_args():
    """å‘½ä»¤è¡Œå‚æ•°è§£æï¼ˆç”¨äºç‹¬ç«‹æµ‹è¯•ï¼‰"""
    parser = argparse.ArgumentParser(description="AI æœè£…å»ºè®®å·¥å…·")
    parser.add_argument(
        "--ai-mode",
        default="ollama",
        choices=["ollama", "local", "openai"],
        help="AIæ¨¡å¼é€‰æ‹© (ollama=æœ¬åœ°Ollama+Gemma, openai=OpenAI API)",
    )
    parser.add_argument("--city", default="Tokyo")
    parser.add_argument("--lang", default="ja", choices=["ja", "zh", "en"])
    parser.add_argument("--temp", type=float, default=21)
    parser.add_argument("--desc", default="cloudy")
    parser.add_argument("--verbose", "-v", action="store_true", help="æ˜¾ç¤ºè¯¦ç»†ä¿¡æ¯")
    return parser.parse_args()


def main():
    """ç‹¬ç«‹æµ‹è¯•åŠŸèƒ½"""
    args = parse_args()

    # æ¨¡æ‹Ÿå¤©æ°”æ•°æ®
    time_remarks = {
        "ja": "å¤œã¯å†·ãˆè¾¼ã‚€ã§ã—ã‚‡ã†",
        "zh": "æ™šä¸Šæ°”æ¸©ä¼šä¸‹é™",
        "en": "Evening temperatures expected to drop",
    }

    time_remark = time_remarks.get(args.lang, time_remarks["ja"])

    if args.verbose:
        print("ğŸŒŸ å¢å¼ºç‰ˆAIæç¤ºè¯:")
        prompt = build_enhanced_prompt(
            args.city, args.temp, args.desc, time_remark, args.lang
        )
        print(prompt)
        print("\n" + "=" * 50)

    suggestion = get_ai_suggestion(
        args.city, args.temp, args.desc, time_remark, args.lang, args.ai_mode
    )
    if suggestion:
        success_msgs = {
            "ja": f"ğŸ¤– AIå»ºè­°: {suggestion}",
            "zh": f"ğŸ¤– AIå»ºè®®: {suggestion}",
            "en": f"ğŸ¤– AI Suggestion: {suggestion}",
        }
        print(success_msgs.get(args.lang, success_msgs["ja"]))
    else:
        error_msgs = {
            "ja": "âŒ AIå»ºè­°ã‚’å–å¾—ã§ãã¾ã›ã‚“ã§ã—ãŸ",
            "zh": "âŒ ç„¡æ³•è·å–AIå»ºè®®",
            "en": "âŒ Unable to get AI suggestion",
        }
        print(error_msgs.get(args.lang, error_msgs["ja"]))


if __name__ == "__main__":
    main()
